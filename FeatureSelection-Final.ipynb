{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9996, 1812)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>bitter</th>\n",
       "      <th>meaty</th>\n",
       "      <th>piquant</th>\n",
       "      <th>salty</th>\n",
       "      <th>sour</th>\n",
       "      <th>sweet</th>\n",
       "      <th>ingredientcount</th>\n",
       "      <th>numberofservings</th>\n",
       "      <th>totaltimeinseconds</th>\n",
       "      <th>...</th>\n",
       "      <th>yolks</th>\n",
       "      <th>yoplait</th>\n",
       "      <th>york</th>\n",
       "      <th>yukon</th>\n",
       "      <th>za</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>course_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating    bitter     meaty  piquant     salty      sour     sweet  \\\n",
       "0       4       NaN       NaN      NaN       NaN       NaN       NaN   \n",
       "1       4  0.833333  0.833333      0.0  0.833333  0.166667  0.166667   \n",
       "\n",
       "   ingredientcount  numberofservings  totaltimeinseconds     ...      yolks  \\\n",
       "0                5               1.0               900.0     ...        0.0   \n",
       "1                5              12.0               300.0     ...        0.0   \n",
       "\n",
       "    yoplait  york  yukon   za  zest  zesty  ziti  zucchini  course_num  \n",
       "0  0.354794   0.0    0.0  0.0   0.0    0.0   0.0       0.0           2  \n",
       "1  0.000000   0.0    0.0  0.0   0.0    0.0   0.0       0.0           3  \n",
       "\n",
       "[2 rows x 1812 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('Unnamed: 0', 1)\n",
    "print data.shape \n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>bitter</th>\n",
       "      <th>meaty</th>\n",
       "      <th>piquant</th>\n",
       "      <th>salty</th>\n",
       "      <th>sour</th>\n",
       "      <th>sweet</th>\n",
       "      <th>ingredientcount</th>\n",
       "      <th>numberofservings</th>\n",
       "      <th>totaltimeinseconds</th>\n",
       "      <th>...</th>\n",
       "      <th>yolks</th>\n",
       "      <th>yoplait</th>\n",
       "      <th>york</th>\n",
       "      <th>yukon</th>\n",
       "      <th>za</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>course_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9996.000000</td>\n",
       "      <td>6763.000000</td>\n",
       "      <td>6763.000000</td>\n",
       "      <td>6763.000000</td>\n",
       "      <td>6763.000000</td>\n",
       "      <td>6763.000000</td>\n",
       "      <td>6763.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9994.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "      <td>9996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.913766</td>\n",
       "      <td>0.425452</td>\n",
       "      <td>0.379467</td>\n",
       "      <td>0.133989</td>\n",
       "      <td>0.450959</td>\n",
       "      <td>0.426142</td>\n",
       "      <td>0.368525</td>\n",
       "      <td>8.527311</td>\n",
       "      <td>6.899940</td>\n",
       "      <td>2890.522209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>1.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.489578</td>\n",
       "      <td>0.282824</td>\n",
       "      <td>0.275017</td>\n",
       "      <td>0.255023</td>\n",
       "      <td>0.286736</td>\n",
       "      <td>0.290511</td>\n",
       "      <td>0.246625</td>\n",
       "      <td>3.674521</td>\n",
       "      <td>21.517772</td>\n",
       "      <td>7613.724316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.043130</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.042310</td>\n",
       "      <td>1.414249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>504000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647370</td>\n",
       "      <td>0.578249</td>\n",
       "      <td>0.441548</td>\n",
       "      <td>0.506644</td>\n",
       "      <td>0.439423</td>\n",
       "      <td>0.526785</td>\n",
       "      <td>0.443969</td>\n",
       "      <td>0.461875</td>\n",
       "      <td>0.570819</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rating       bitter        meaty      piquant        salty  \\\n",
       "count  9996.000000  6763.000000  6763.000000  6763.000000  6763.000000   \n",
       "mean      3.913766     0.425452     0.379467     0.133989     0.450959   \n",
       "std       0.489578     0.282824     0.275017     0.255023     0.286736   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       4.000000     0.166667     0.166667     0.000000     0.166667   \n",
       "50%       4.000000     0.333333     0.166667     0.000000     0.333333   \n",
       "75%       4.000000     0.666667     0.666667     0.166667     0.833333   \n",
       "max       5.000000     1.000000     1.000000     0.833333     1.000000   \n",
       "\n",
       "              sour        sweet  ingredientcount  numberofservings  \\\n",
       "count  6763.000000  6763.000000      9996.000000       9994.000000   \n",
       "mean      0.426142     0.368525         8.527311          6.899940   \n",
       "std       0.290511     0.246625         3.674521         21.517772   \n",
       "min       0.000000     0.000000         1.000000          1.000000   \n",
       "25%       0.166667     0.166667         6.000000          4.000000   \n",
       "50%       0.333333     0.166667         8.000000          4.000000   \n",
       "75%       0.666667     0.500000        10.000000          6.000000   \n",
       "max       1.000000     1.000000        51.000000        750.000000   \n",
       "\n",
       "       totaltimeinseconds     ...             yolks      yoplait         york  \\\n",
       "count         9996.000000     ...       9996.000000  9996.000000  9996.000000   \n",
       "mean          2890.522209     ...          0.004273     0.000709     0.000223   \n",
       "std           7613.724316     ...          0.037981     0.017120     0.009155   \n",
       "min             60.000000     ...          0.000000     0.000000     0.000000   \n",
       "25%           1200.000000     ...          0.000000     0.000000     0.000000   \n",
       "50%           1800.000000     ...          0.000000     0.000000     0.000000   \n",
       "75%           3000.000000     ...          0.000000     0.000000     0.000000   \n",
       "max         504000.000000     ...          0.647370     0.578249     0.441548   \n",
       "\n",
       "             yukon           za         zest        zesty         ziti  \\\n",
       "count  9996.000000  9996.000000  9996.000000  9996.000000  9996.000000   \n",
       "mean      0.001481     0.000157     0.006294     0.000229     0.000046   \n",
       "std       0.022700     0.007905     0.043130     0.009373     0.004620   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.506644     0.439423     0.526785     0.443969     0.461875   \n",
       "\n",
       "          zucchini   course_num  \n",
       "count  9996.000000  9996.000000  \n",
       "mean      0.005431     1.999700  \n",
       "std       0.042310     1.414249  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     1.000000  \n",
       "50%       0.000000     2.000000  \n",
       "75%       0.000000     3.000000  \n",
       "max       0.570819     4.000000  \n",
       "\n",
       "[8 rows x 1812 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extra Tree Classifier\n",
    "array = data.values\n",
    "x = array[:,0:1811]\n",
    "y = array[:,1811]\n",
    "# #feature extraction\n",
    "# model = ExtraTreesClassifier()\n",
    "# mdl = model.fit(x,y)\n",
    "# importances = mdl.feature_importances_\n",
    "# print(importances)\n",
    "\n",
    "# model = SelectFromModel(mdl, prefit=True)\n",
    "# X_new = model.transform(x)\n",
    "# print X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7497, 1811)\n",
      "(2499, 1811)\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(x, y, random_state=10)\n",
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select models to test on dataset\n",
    "models=[]\n",
    "models.append(('LOG', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('NB', GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: 0.853269 (0.018951)\n",
      "LDA: 0.847272 (0.010730)\n",
      "CART: 0.770443 (0.017189)\n",
      "KNN: 0.454181 (0.012633)\n",
      "SVM: 0.353609 (0.007109)\n",
      "NB: 0.518728 (0.059067)\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "results=[]\n",
    "names=[]\n",
    "for name, model in models:\n",
    "    kfold = KFold(n = 7497, n_folds = 10, random_state = 10)\n",
    "    _results = cross_validation.cross_val_score(model, X_train, Y_train, cv = kfold, scoring = 'accuracy')\n",
    "    results.append(_results)\n",
    "    names.append(name)\n",
    "    scores=\"%s: %f (%f)\" % (name, _results.mean(), _results.std())\n",
    "    print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a pipeline \n",
    "pipelines=[]\n",
    "pipelines.append(('ScaledLOG', Pipeline([('Scaler', StandardScaler()),('LOG', LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()),('LDA', LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())])))\n",
    "pipelines.append(('ScaledGNB', Pipeline([('Scaler', StandardScaler()),('GNB', GaussianNB())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLOG: 0.834466 (0.012616)\n",
      "ScaledLDA: 0.847272 (0.010730)\n",
      "ScaledCART: 0.768708 (0.017606)\n",
      "ScaledKNN: 0.690275 (0.013966)\n",
      "ScaledSVM: 0.823528 (0.012014)\n",
      "ScaledGNB: 0.584233 (0.022016)\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "names=[]\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n=7497,n_folds=10, random_state=10)\n",
    "    _results=cross_validation.cross_val_score(model,X_train,Y_train,cv=kfold,scoring='accuracy')\n",
    "    results.append(_results)\n",
    "    names.append(name)\n",
    "    scores=\"%s: %f (%f)\" % (name, _results.mean(), _results.std())\n",
    "    print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try ensemble methods\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "ensembles = []\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.720033 (0.018775)\n",
      "GBM: 0.864677 (0.008707)\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "names=[]\n",
    "for name, model in ensembles:\n",
    "    kfold=KFold(n=7508,n_folds=10, random_state=10)\n",
    "    _results=cross_validation.cross_val_score(model,X_train,Y_train,cv=kfold,scoring='accuracy')\n",
    "    results.append(_results)\n",
    "    names.append(name)\n",
    "    scores=\"%s: %f (%f)\" % (name, _results.mean(), _results.std())\n",
    "    print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gridsearch for GBM\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                                               min_samples_split=500,\n",
    "                                                               min_samples_leaf=50,\n",
    "                                                               max_depth=8,max_features='sqrt',\n",
    "                                                               subsample=0.8,\n",
    "                                                               random_state=10), \n",
    "                        param_grid = param_test1, scoring='roc_auc', n_jobs=4, iid=False, cv=10)\n",
    "\n",
    "gsearch1.fit(X_train,Y_train)\n",
    "\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860477524343\n",
      "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "{'C': 1000.0}\n"
     ]
    }
   ],
   "source": [
    "#Tune Logistic regression\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "alphas = np.array([0.1, 1.0,10.0,100.0,1000.0])\n",
    "param_grid = dict(C=alphas)\n",
    "model = LogisticRegression()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid.fit(X_train, Y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499\n",
      "0.858343337335\n",
      "[[417  12  11  47  19]\n",
      " [ 28 421  29  12  10]\n",
      " [  6  55 448   3   0]\n",
      " [ 66   3   6 405  17]\n",
      " [  9   5   4  12 454]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.82      0.81       506\n",
      "        1.0       0.85      0.84      0.85       500\n",
      "        2.0       0.90      0.88      0.89       512\n",
      "        3.0       0.85      0.81      0.83       497\n",
      "        4.0       0.91      0.94      0.92       484\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = grid.best_estimator_\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "print len(Y_pred)\n",
    "\n",
    "print accuracy_score(Y_test, Y_pred )\n",
    "print confusion_matrix(Y_test,Y_pred )\n",
    "print classification_report(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Bagging Model Accuracy on training data\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.80      0.80       506\n",
      "        1.0       0.86      0.83      0.85       500\n",
      "        2.0       0.90      0.90      0.90       512\n",
      "        3.0       0.84      0.85      0.84       497\n",
      "        4.0       0.90      0.93      0.91       484\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Apply ensemble method- Bagging \n",
    "\n",
    "def build_bagging_model(x,y):\n",
    "    bagging = BaggingClassifier(LogisticRegression(),\n",
    "                                n_estimators = 100, \n",
    "                                random_state = 10,\n",
    "                                max_samples = 1.0,\n",
    "                                max_features = 0.7,\n",
    "                                bootstrap = True,\n",
    "                                bootstrap_features = True)\n",
    "    bagging.fit(x,y)\n",
    "    return bagging\n",
    "\n",
    "# Build a bag of Logreg models\n",
    "bagging = build_bagging_model(X_train, Y_train)\n",
    "predicted_y = bagging.predict(X_test)\n",
    "\n",
    "print \"\\n Bagging Model Accuracy on training data\\n\"\n",
    "print classification_report(Y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
