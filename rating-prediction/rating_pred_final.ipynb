{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('brownie_ingred_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('recipe_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1.drop('Unnamed: 0', inplace=True, axis = 1)\n",
    "df_1.set_index('Unnamed: 0.1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2.drop('Unnamed: 0', inplace=True, axis = 1)\n",
    "df_2.set_index('Unnamed: 0.1', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join and clean joined df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_3 = df_2.join(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_3.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_3.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_name</th>\n",
       "      <th>tot_time_seconds</th>\n",
       "      <th>rec_source</th>\n",
       "      <th>rating</th>\n",
       "      <th>1% low-fat milk</th>\n",
       "      <th>2% lowfat greek yogurt</th>\n",
       "      <th>2% reduced-fat milk</th>\n",
       "      <th>active dry yeast</th>\n",
       "      <th>adobo sauce</th>\n",
       "      <th>adzuki beans</th>\n",
       "      <th>...</th>\n",
       "      <th>wilton candy eyeballs</th>\n",
       "      <th>xanthan gum</th>\n",
       "      <th>xylitol sweetener</th>\n",
       "      <th>yams</th>\n",
       "      <th>yellow cake mix</th>\n",
       "      <th>yellow food coloring</th>\n",
       "      <th>yoghurt</th>\n",
       "      <th>yolk</th>\n",
       "      <th>yoplait</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Minute Chocolate Frosting</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Spend with Pennies</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Minute Microwave Brownie-Microwave Mug Meals</td>\n",
       "      <td>360.0</td>\n",
       "      <td>Gemma's Bigger Bolder Baking</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         rec_name  tot_time_seconds  \\\n",
       "0                     1 Minute Chocolate Frosting              60.0   \n",
       "1  1 Minute Microwave Brownie-Microwave Mug Meals             360.0   \n",
       "\n",
       "                     rec_source  rating  1% low-fat milk  \\\n",
       "0            Spend with Pennies       4              0.0   \n",
       "1  Gemma's Bigger Bolder Baking       4              0.0   \n",
       "\n",
       "   2% lowfat greek yogurt  2% reduced-fat milk  active dry yeast  adobo sauce  \\\n",
       "0                     0.0                  0.0               0.0          0.0   \n",
       "1                     0.0                  0.0               0.0          0.0   \n",
       "\n",
       "   adzuki beans    ...     wilton candy eyeballs  xanthan gum  \\\n",
       "0           0.0    ...                       0.0          0.0   \n",
       "1           0.0    ...                       0.0          0.0   \n",
       "\n",
       "   xylitol sweetener  yams  yellow cake mix  yellow food coloring  yoghurt  \\\n",
       "0                0.0   0.0              0.0                   0.0      0.0   \n",
       "1                0.0   0.0              0.0                   0.0      0.0   \n",
       "\n",
       "   yolk  yoplait  zucchini  \n",
       "0   0.0      0.0       0.0  \n",
       "1   0.0      0.0       0.0  \n",
       "\n",
       "[2 rows x 1138 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.reset_index(inplace=True, drop=True)\n",
    "df_3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering - recipe sources that consistently score a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solid_fives = ['My Baking Addiction', 'Recipe Girl', 'La Tartine Gourmande',\n",
    "              'Closet Cooking', 'Our Best Bites', 'David Lebovitz',\n",
    "              'I Adore Food!']\n",
    "solid_threes = ['Tablespoon', 'Tasty Kitchen', 'Southern Food About.com',\n",
    "               'Cooking Channel', 'Dinner Then Dessert', 'Diabetic Connect']\n",
    "solid_fours = ['Brown Eyed Baker', 'Recipe for Perfection', 'Something Swanky',\n",
    "              'Broma Bakery', 'a trEATs affair', 'The Domestic Rebel',\n",
    "              'Dinners, Dishes and Desserts', 'Love and Olive Oil', \n",
    "              'Life Made Simple', \"Roxana's Home Baking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create column of zeros and ones for rec_source membership in solid_fives list\n",
    "fives_boolean = df_3.rec_source.isin(solid_fives)\n",
    "fives_dummy = [1 if z==True else 0 for z in fives_boolean]\n",
    "df_3['solid_fives'] = fives_dummy\n",
    "\n",
    "# Do same for solid_fours and solid_threes\n",
    "fours_boolean = df_3.rec_source.isin(solid_fours)\n",
    "fours_dummy = [1 if z==True else 0 for z in fours_boolean]\n",
    "df_3['solid_fours'] = fours_dummy\n",
    "\n",
    "threes_boolean = df_3.rec_source.isin(solid_threes)\n",
    "threes_dummy = [1 if z==True else 0 for z in threes_boolean]\n",
    "df_3['solid_threes'] = threes_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add number of ingredients column, also remove rare ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create column for number of ingredients\n",
    "df_3['num_ingredients'] = df_3.iloc[:, 4:-9].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quickly drop zeros and twos, since there are so few\n",
    "df_3 = df_3.loc[df_3.rating != 0]\n",
    "df_3 = df_3.loc[df_3.rating != 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process text data for bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# strip non alpha characters\n",
    "name_string = [re.sub('[^A-Za-z]', ' ', z).strip().lower() for z in df_3['rec_name']]\n",
    "\n",
    "# convert to list so you can iterate through with lemmatization\n",
    "convert_to_list = [z.split() for z in name_string]\n",
    "\n",
    "# lemmatize each word in list\n",
    "lemmatized = []\n",
    "for _list in convert_to_list:\n",
    "    sub_list = []\n",
    "    for word in _list:\n",
    "        sub_list.append(WordNetLemmatizer().lemmatize(word))\n",
    "    lemmatized.append(sub_list)\n",
    "    \n",
    "df_3['name_str'] = [' '.join(z) for z in lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=.5)\n",
    "\n",
    "# create document term matrix\n",
    "dtm = vect.fit_transform(df_3.name_str).toarray()\n",
    "\n",
    "# convert to dataframe\n",
    "clean_df = pd.DataFrame(dtm, columns = vect.get_feature_names())\n",
    "\n",
    "# add columns to dataframe\n",
    "clean_df['num_ingred'] = df_3.num_ingredients\n",
    "clean_df['solid_five'] = df_3.solid_fives\n",
    "clean_df['solid_four'] = df_3.solid_fours\n",
    "clean_df['solid_three'] = df_3.solid_threes\n",
    "clean_df['rating'] = df_3.rating\n",
    "\n",
    "# drop any NaNs from dataframe\n",
    "clean_df.dropna(axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create features and target\n",
    "X, y = clean_df.drop(['rating'], axis=1), clean_df.rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce features L1-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4794, 4)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit LinearSVC\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "\n",
    "# use SelectFromModel to extract features\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "\n",
    "# transform X to new feature space\n",
    "X_new = model.transform(X)\n",
    "\n",
    "# check shape\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5038, 5039, 5040, 5041])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_support(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look, it's only the features I added, none of the text data was worth while\n",
    "reduced_df = X.iloc[:, (5038, 5039, 5040, 5041)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Multinomial Naive Bayes, Bernoulli NB, Logistic Regression, and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77604167,  0.78125   ,  0.77685089,  0.78810021,  0.77638454])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(mnb, X_new, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77604167,  0.78125   ,  0.77685089,  0.78810021,  0.77638454])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bnb, X_new, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77604167,  0.78125   ,  0.77685089,  0.78810021,  0.77638454])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, X_new, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf = SVC(C=1)\n",
    "# gamma_range = 10.**np.arange(-3, 2)\n",
    "# kernel_range = ['rbf', 'linear', 'poly']\n",
    "# param_grid = dict(gamma=gamma_range)\n",
    "# grid = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "# grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71354167,  0.6875    ,  0.72888425,  0.75156576,  0.70532915])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators':[3, 5, 10, 50],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 5],\n",
    "          'min_samples_split': [2,5],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "\n",
    "gsrf = GridSearchCV(RandomForestClassifier(n_jobs=-1),\n",
    "                    params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [3, 5, 10, 50], 'min_samples_split': [2, 5], 'criterion': ['gini', 'entropy'], 'max_depth': [None, 3, 5], 'class_weight': [None, 'balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.fit(X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77972465581977468"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsrf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate mistakes the classifier made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genertate predictions with cross_val_predict\n",
    "logit = LogisticRegression()\n",
    "predictions = cross_val_predict(logit, X_new, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# add predictions and true ratings to reduced_df\n",
    "reduced_df['predictions'] = predictions\n",
    "reduced_df['rating'] = df_3.rating\n",
    "reduced_df['rec_name'] = df_3.rec_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingred</th>\n",
       "      <th>solid_five</th>\n",
       "      <th>solid_four</th>\n",
       "      <th>solid_three</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.026846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.214521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_ingred  solid_five  solid_four  solid_three  predictions\n",
       "rating                                                              \n",
       "3         9.026846         0.0         0.0          0.0          4.0\n",
       "4         8.375000         1.0         0.0          0.0          5.0\n",
       "5         9.214521         0.0         0.0          0.0          4.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df[reduced_df.predictions != reduced_df.rating].groupby('rating').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4794, 7)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
