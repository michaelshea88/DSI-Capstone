{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data, merge two dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('brownie_ingred_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('recipe_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_3 = pd.merge(df_1, df_2, on='Unnamed: 0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new features based on sources that consistently rank a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllRecipes                  180\n",
       "MyRecipes                    92\n",
       "Betty Crocker                57\n",
       "Taste of Home                53\n",
       "Bake or Break                52\n",
       "Martha Stewart               50\n",
       "Brown Eyed Baker             42\n",
       "Recipe Girl                  36\n",
       "Inside BruCrew Life          32\n",
       "Better Homes and Gardens     29\n",
       "Epicurious                   29\n",
       "My Baking Addiction          29\n",
       "Recipe for Perfection        29\n",
       "Crazy For Crust              28\n",
       "How Sweet It Is              26\n",
       "Name: rec_source, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.rec_source.value_counts()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count_nonzero</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I Adore Food!</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David Lebovitz</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Our Best Bites</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Closet Cooking</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Tartine Gourmande</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean  count_nonzero  std\n",
       "rec_source                                    \n",
       "I Adore Food!          5.0              5  0.0\n",
       "David Lebovitz         5.0              4  0.0\n",
       "Our Best Bites         5.0              4  0.0\n",
       "Closet Cooking         5.0              2  0.0\n",
       "La Tartine Gourmande   5.0              2  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performed several groupbys to identify recipe sources that had brownie recipes all of one ranking\n",
    "# standard deviation would equal zero in these cases - chose the ones with the highest value counts\n",
    "grouped = df_3.groupby('rec_source')\n",
    "grouped['rating'].agg([np.mean, np.count_nonzero, np.std]).sort_values(by=['mean', 'count_nonzero'], \n",
    "                                                                       ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solid_fives = ['My Baking Addiction', 'Recipe Girl', 'La Tartine Gourmande',\n",
    "              'Closet Cooking', 'Our Best Bites', 'David Lebovitz',\n",
    "              'I Adore Food!']\n",
    "solid_threes = ['Tablespoon', 'Tasty Kitchen', 'Southern Food About.com',\n",
    "               'Cooking Channel', 'Dinner Then Dessert', 'Diabetic Connect']\n",
    "solid_fours = ['Brown Eyed Baker', 'Recipe for Perfection', 'Something Swanky',\n",
    "              'Broma Bakery', 'a trEATs affair', 'The Domestic Rebel',\n",
    "              'Dinners, Dishes and Desserts', 'Love and Olive Oil', \n",
    "              'Life Made Simple', \"Roxana's Home Baking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create column of zeros and ones for rec_source membership in solid_fives list\n",
    "fives_boolean = df_3.rec_source.isin(solid_fives)\n",
    "fives_dummy = [1 if z==True else 0 for z in fives_boolean]\n",
    "df_3['solid_fives'] = fives_dummy\n",
    "\n",
    "# Do same for solid_fours and solid_threes\n",
    "fours_boolean = df_3.rec_source.isin(solid_fours)\n",
    "fours_dummy = [1 if z==True else 0 for z in fours_boolean]\n",
    "df_3['solid_fours'] = fours_dummy\n",
    "\n",
    "threes_boolean = df_3.rec_source.isin(solid_threes)\n",
    "threes_dummy = [1 if z==True else 0 for z in threes_boolean]\n",
    "df_3['solid_threes'] = threes_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features based on whether \"healthy\" is in the name of the brownie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First check if \"best\" is exclusive to a certain rank, not so much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2.set_index(\"Unnamed: 0.1\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contains_best = []\n",
    "for i in df_2.index:\n",
    "    if 'est' in i:\n",
    "        contains_best.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contains_best_df = df_2.ix[contains_best, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rec_name</th>\n",
       "      <th>tot_time_seconds</th>\n",
       "      <th>rec_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  rec_name  tot_time_seconds  rec_source\n",
       "rating                                                    \n",
       "3               11        11                11          11\n",
       "4               97        97                97          97\n",
       "5               10        10                10          10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_best_df.groupby('rating').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contains_healthy = []\n",
    "for i in df_2.index:\n",
    "    if 'ealth' in i:\n",
    "        contains_healthy.append(i)\n",
    "contains_healthy_df = df_2.ix[contains_healthy, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rec_name</th>\n",
       "      <th>tot_time_seconds</th>\n",
       "      <th>rec_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  rec_name  tot_time_seconds  rec_source\n",
       "rating                                                    \n",
       "3                6         6                 6           6\n",
       "4               49        49                49          49"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_healthy_df.groupby('rating').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add to dataframe\n",
    "healthy_boolean = df_3[\"Unnamed: 0.1\"].isin(contains_healthy)\n",
    "healthy_dummy = [1 if z==True else 0 for z in healthy_boolean]\n",
    "df_3['healthy_in_name'] = healthy_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4952\n",
       "True       55\n",
       "Name: Unnamed: 0.1, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_boolean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>1% low-fat milk</th>\n",
       "      <th>2% lowfat greek yogurt</th>\n",
       "      <th>2% reduced-fat milk</th>\n",
       "      <th>active dry yeast</th>\n",
       "      <th>adobo sauce</th>\n",
       "      <th>adzuki beans</th>\n",
       "      <th>agave nectar</th>\n",
       "      <th>all-purpose flour</th>\n",
       "      <th>...</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>rec_name</th>\n",
       "      <th>tot_time_seconds</th>\n",
       "      <th>rec_source</th>\n",
       "      <th>rating</th>\n",
       "      <th>solid_fives</th>\n",
       "      <th>solid_fours</th>\n",
       "      <th>solid_threes</th>\n",
       "      <th>healthy_in_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2-Ingredient-Nutella-Brownies-1471916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2 Ingredient Nutella Brownies</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>Baking Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x                           Unnamed: 0.1  1% low-fat milk  \\\n",
       "0             0  2-Ingredient-Nutella-Brownies-1471916                0   \n",
       "\n",
       "   2% lowfat greek yogurt  2% reduced-fat milk  active dry yeast  adobo sauce  \\\n",
       "0                       0                    0                 0            0   \n",
       "\n",
       "   adzuki beans  agave nectar  all-purpose flour       ...         zucchini  \\\n",
       "0             0             0                  0       ...                0   \n",
       "\n",
       "   Unnamed: 0_y                       rec_name  tot_time_seconds  \\\n",
       "0           416  2 Ingredient Nutella Brownies            2700.0   \n",
       "\n",
       "      rec_source  rating  solid_fives  solid_fours  solid_threes  \\\n",
       "0  Baking Beauty       4            0            0             0   \n",
       "\n",
       "   healthy_in_name  \n",
       "0                0  \n",
       "\n",
       "[1 rows x 1145 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create column for number of ingredients\n",
    "df_3['num_ingredients'] = df_3.iloc[:, 2:-9].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prelim Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#quickly drop a few NaNs\n",
    "df_3.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#quickly drop zeros and twos, since there are so few\n",
    "df_3 = df_3.loc[df_3.rating != 0]\n",
    "df_3 = df_3.loc[df_3.rating != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3753\n",
       "3     823\n",
       "5     373\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check and see if they dropped properly\n",
    "df_3.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple kNN to get baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_3.drop(['Unnamed: 0_x', 'Unnamed: 0.1', 'Unnamed: 0_y', 'rec_name', \n",
    "           'rating', 'rec_source', 'tot_time_seconds'], axis=1)\n",
    "y = df_3.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75479314,  0.75782038,  0.75580222,  0.76315789,  0.76012146])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "name_string = [re.sub('[^A-Za-z]', ' ', z).strip().lower() for z in df_3['rec_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-dccfa9e7e581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'name_str' is not defined"
     ]
    }
   ],
   "source": [
    "convert_to_list = [z.split() for z in name_string]\n",
    "\n",
    "lemmatized = []\n",
    "for _list in convert_to_list:\n",
    "    sub_list = []\n",
    "    for word in _list:\n",
    "        sub_list.append(WordNetLemmatizer().lemmatize(word))\n",
    "    lemmatized.append(sub_list)\n",
    "    \n",
    "name_str = [' '.join(z) for z in lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_3['solid_fives', 'solid_fours', 'solid_threes', 'num_ingredients', 'tot_time_seconds',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple logistic regression,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77598385,  0.79515641,  0.7679112 ,  0.77834008,  0.76518219])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'penalty': ['l1', 'l2']}\n",
    "gslr = GridSearchCV(logit, params, n_jobs=-1, cv=KFold(len(y), n_folds=3, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=4949, n_folds=3, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gslr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78015760759749442"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gslr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap logistic regression in a bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagging_params = {'n_estimators': [10, 20], 'max_samples': [0.7, 1.0], 'max_features': [0.7, 1.0],\n",
    "                  'bootstrap_features': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsbagginglr = GridSearchCV(BaggingClassifier(gslr.best_estimator_),\n",
    "                           bagging_params, n_jobs=-1, cv=KFold(len(y), n_folds=3, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=4949, n_folds=3, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start...n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [10, 20], 'max_samples': [0.7, 1.0], 'bootstrap_features': [True, False], 'max_features': [0.7, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsbagginglr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779955546575\n"
     ]
    }
   ],
   "source": [
    "print gsbagginglr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## takeaways from prelim modelling:\n",
    "\n",
    "very little improvement over guessing most common class every time (rating of four) --  i.e. 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelim modelling no better than baseline - try feature selection (only marginal improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=100).fit_transform(X, y).get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78203835,  0.80221998,  0.77800202,  0.78947368,  0.77935223])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logit, X_new, y, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try random forest, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfclass = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76690212,  0.78708375,  0.76185671,  0.77226721,  0.75809717])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfclass, X_new, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Users/michaelshea/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.784 +/- 0.00857\n"
     ]
    }
   ],
   "source": [
    "cvscores = cross_val_score(svm, X_new, y, cv = 5, n_jobs=-1)\n",
    "print \"CV score: {:.3} +/- {:.3}\".format(cvscores.mean(), cvscores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
